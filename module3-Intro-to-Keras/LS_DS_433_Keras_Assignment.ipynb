{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [],
   "source": [
    "# Following Jason Browlee's tutorial on Keras Regression\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datset\n",
    "df = pd.read_csv('housing.csv', delim_whitespace=True, header=None)\n",
    "dataset = df.values\n",
    "# split into input(X) and output(Y) variables\n",
    "X = dataset[:, 0:13]\n",
    "Y = dataset[:, 13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom keras.datasets import boston_housing\\n\\n(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from keras.datasets import boston_housing\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(102, 13)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use a scikit learn workflow with Keras by using a Keras wrapper object that comes with scikit-learn\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "#evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model:\n",
      "\n",
      "Mean of MSE: -32.52 Standard Deviation of : 23.28\n"
     ]
    }
   ],
   "source": [
    "# the final step is to evaluate the baseline model with 10-fold cross validation\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Baseline model:\\n\")\n",
    "print(\"Mean of MSE: {:.2f} Standard Deviation of : {:.2f}\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of MSE: -29.67 Standard Deviation of : 27.91\n"
     ]
    }
   ],
   "source": [
    "# Let's standardize the data with mean zero and standard deviation 1\n",
    "\n",
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Mean of MSE: {:.2f} Standard Deviation of : {:.2f}\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "batch_size= 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Flatten the images\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_103 (Dense)            (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 13,002\n",
      "Trainable params: 13,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2)) ## Added dropout\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 8s 143us/step - loss: 1.0080 - acc: 0.6210 - val_loss: 0.5540 - val_acc: 0.7978\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 5s 102us/step - loss: 0.7450 - acc: 0.7147 - val_loss: 0.5212 - val_acc: 0.8062\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 6s 114us/step - loss: 0.6816 - acc: 0.7456 - val_loss: 0.4906 - val_acc: 0.8188\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 6s 103us/step - loss: 0.6509 - acc: 0.7564 - val_loss: 0.5193 - val_acc: 0.8203\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 6s 104us/step - loss: 0.6394 - acc: 0.7599 - val_loss: 0.4647 - val_acc: 0.8398\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 6s 105us/step - loss: 0.6258 - acc: 0.7685 - val_loss: 0.4628 - val_acc: 0.8353\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 6s 103us/step - loss: 0.6132 - acc: 0.7733 - val_loss: 0.4577 - val_acc: 0.8397\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 6s 103us/step - loss: 0.6051 - acc: 0.7751 - val_loss: 0.4554 - val_acc: 0.8398\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 6s 103us/step - loss: 0.6003 - acc: 0.7755 - val_loss: 0.4537 - val_acc: 0.8392\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 6s 103us/step - loss: 0.5929 - acc: 0.7782 - val_loss: 0.4415 - val_acc: 0.8443\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 6s 103us/step - loss: 0.5832 - acc: 0.7806 - val_loss: 0.4525 - val_acc: 0.8418\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 6s 103us/step - loss: 0.5811 - acc: 0.7824 - val_loss: 0.4519 - val_acc: 0.8422\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 6s 103us/step - loss: 0.5775 - acc: 0.7864 - val_loss: 0.4685 - val_acc: 0.8350\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 6s 103us/step - loss: 0.5730 - acc: 0.7858 - val_loss: 0.4372 - val_acc: 0.8452\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 6s 103us/step - loss: 0.5734 - acc: 0.7839 - val_loss: 0.4438 - val_acc: 0.8538\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 6s 103us/step - loss: 0.5705 - acc: 0.7885 - val_loss: 0.4309 - val_acc: 0.8515\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 6s 103us/step - loss: 0.5668 - acc: 0.7903 - val_loss: 0.4336 - val_acc: 0.8443\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 6s 103us/step - loss: 0.5632 - acc: 0.7905 - val_loss: 0.4384 - val_acc: 0.8470\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 6s 104us/step - loss: 0.5607 - acc: 0.7901 - val_loss: 0.4264 - val_acc: 0.8493\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 6s 105us/step - loss: 0.5563 - acc: 0.7909 - val_loss: 0.4340 - val_acc: 0.8467\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "acc: 84.31\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=epochs, validation_split=.1)\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(f'{model.metrics_names[1]}: {scores[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "training_loss = history.history['loss']\n",
    "#test_loss = history.history['val_loss']\n",
    "\n",
    "epoch_count = range(1, len(training_loss) +1)\n",
    "\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "#plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
